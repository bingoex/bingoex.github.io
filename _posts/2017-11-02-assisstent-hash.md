---
layout: post
title: 一致性hash算法
categories: 数学/算法 计算机网络 系统架构
description: 
keywords: 
---


# 分布式算法

服务器的**负载均衡的算法**有很多，包括： **轮循算法(Round Robin)、哈希算法(HASH)、最少连接算法(Least Connection)、响应速度算法(Response Time)、加权法(Weighted )**等。其中哈希算法是最为常用的算法。
 
**典型的应用场景是： 有N台服务器提供缓存服务，需要对服务器进行负载均衡，将请求平均分发到每台服务器上，每台机器负责1/N的服务**。常用的算法是对hash结果取余数 (hash() mod N )：对机器编号从0到N-1，按照自定义的hash()算法，对每个请求的hash()值按N取模，得到余数i，然后将请求分发到编号为i的机器。
 
但这样的算法方法存在**致命问题**，**如果某一台机器宕机（或者新增一台机器）**，那么应该落在该机器的请求就无法得到正确的处理，这时需要将当掉的服务器从算法从去除，此时候会有服务器的缓存数据需要重新进行计算。对于系统而言，这通常是不可接受的颠簸(因为这意味着**大量缓存的失效或者数据需要转移**)。一个设计良好的分布式哈希方案应该具有良好的**单调性**，即服务节点的增减不会造成大量哈希重定位。一致性哈希算法就是这样一种哈希方案。那么，如何设计一个负载均衡策略，使得受到影响的请求尽可能的少呢？ （在Memcached、Key-Value Store 、Bittorrent DHT、LVS中都采用了Consistent Hashing算法，可以说Consistent Hashing 是分布式系统负载均衡的首选算法）


 
# 一致性哈希算法

一致性哈希算法(ConsistentHashing Algorithm)是一种分布式算法，常用于负载均衡。

Memcached client也选择这种算法，解决将key-value均匀分配到众多Memcached server上的问题。它可以取代传统的取模操作，**解决了取模操作无法应对增删Memcached Server的问题(增删server会导致同一个key,在get操作时分配不到数据真正存储的server，命中率会急剧下降)**。

1、简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - (2^32)-1（即哈希值是一个32位无符号整形），整个哈希空间环如下。

![](/images/posts/2017-11-02-assisstent-hash.md/1.png)

2、下一步将各个服务器使用H进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中三台服务器使用ip地址哈希后在环空间的位置如下： 

![](/images/posts/2017-11-02-assisstent-hash.md/2.png)
 

3、接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。

例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下：

![](/images/posts/2017-11-02-assisstent-hash.md/3.png)
 
根据一致性哈希算法，数据A会被定为到Server 1上，D被定为到Server3上，而B、C分别被定为到Server 2上。
 
## 容错性与可扩展性分析

下面分析一致性哈希算法的容错性和可扩展性。现假设Server 3宕机了：
 
![](/images/posts/2017-11-02-assisstent-hash.md/4.png)

可以看到此时A、C、B不会受到影响，只有D节点被重定位到Server 2。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。


下面考虑另外一种情况，如果我们在系统中增加一台服务器Memcached Server 4： 

![](/images/posts/2017-11-02-assisstent-hash.md/5.png)

此时A、D、C不受影响，只有B需要重定位到新的Server 4。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。

综上所述，一致性哈希算法对于节点的**增减都只需重定位环空间中的一小部分数据**，具有较好的容错性和可扩展性。

 
## 虚拟节点

一致性哈希算法在服务节点太少时，容易因为节点分部**不均匀而造成数据倾斜问题**。例如我们的系统中有两台服务器，其环分布如下： 

![](/images/posts/2017-11-02-assisstent-hash.md/6.png)

此时必然造成大量数据集中到Server 1上，而只有极少量会定位到Server 2上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。

具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，我们决定为每台服务器计算三个虚拟节点，于是可以分别计算“Memcached Server 1#1”、“Memcached Server 1#2”、“Memcached Server 1#3”、“Memcached Server 2#1”、“Memcached Server 2#2”、“Memcached Server 2#3”的哈希值，于是形成六个虚拟节点： 

![](/images/posts/2017-11-02-assisstent-hash.md/7.png)



 
 
 
 
 


